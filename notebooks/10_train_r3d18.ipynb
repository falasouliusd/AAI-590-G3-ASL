{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4e4a89b-be80-4cf5-b7a1-f35bdfb918b0",
   "metadata": {},
   "source": [
    "(compact baseline, torchvision-free)\n",
    "\n",
    "This is a small 3D CNN baseline (C3D-lite). It’s not as strong as an official R(2+1)D/ResNet-3D, but it trains fast and avoids extra library constraints. You can later swap in a stronger backbone with the same dataloaders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4a66cc-3233-432f-a610-fb298a9cc23a",
   "metadata": {},
   "source": [
    "### Cell 1 — Root, config, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9d549ab-4cd5-45a1-b068-8a7538956030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHONPATH added: /home/falasoul/notebooks/USD/AAI-590/Capstone/AAI-590-G3-ASL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Cell 1: project root, sys.path, config, utils ---\n",
    "from pathlib import Path\n",
    "import sys, yaml\n",
    "\n",
    "# 1) Point to project root and add to sys.path BEFORE any src imports\n",
    "root = Path(\"..\").resolve()\n",
    "if str(root) not in sys.path:\n",
    "    sys.path.insert(0, str(root))\n",
    "if str(root / \"src\") not in sys.path:\n",
    "    sys.path.insert(0, str(root / \"src\"))\n",
    "print(\"PYTHONPATH added:\", root)\n",
    "\n",
    "# 2) Now it's safe to import from src/*\n",
    "from src.data.wlasl_ds import WLASLDataset\n",
    "from src.utils.seed import seed_everything\n",
    "from src.utils.checkpoints import save_checkpoint, load_checkpoint\n",
    "\n",
    "# 3) Load config & prepare dirs\n",
    "cfg_path = root / \"configs\" / \"wlasl100.yaml\"\n",
    "assert cfg_path.exists(), f\"Config not found: {cfg_path}\"\n",
    "CFG = yaml.safe_load(open(cfg_path, \"r\"))\n",
    "\n",
    "CKPT_DIR = root / CFG[\"paths\"][\"checkpoints_dir\"]\n",
    "LOG_DIR  = root / CFG[\"paths\"][\"logs_dir\"]\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 4) Seed\n",
    "seed_everything(CFG[\"wlasl\"][\"split_seed\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d87bf12-5754-45f3-8686-12af4c1bf6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports OK; seed: 42\n"
     ]
    }
   ],
   "source": [
    "from src.utils.seed import seed_everything\n",
    "from src.utils.checkpoints import save_checkpoint, load_checkpoint\n",
    "print(\"imports OK; seed:\", seed_everything(42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7dc46fa-5e35-46da-8396-c3248f1218b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, cv2, decord, random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "decord.bridge.set_bridge(\"torch\")\n",
    "\n",
    "def _resize_112(frame_tchw: torch.Tensor) -> torch.Tensor:\n",
    "    # frame_tchw: [T,C,H,W] float32 [0,1]\n",
    "    T,C,H,W = frame_tchw.shape\n",
    "    # Use OpenCV for speed; convert to NHWC\n",
    "    arr = frame_tchw.permute(0,2,3,1).cpu().numpy()  # T,H,W,C\n",
    "    out = np.empty((T,112,112,C), dtype=np.float32)\n",
    "    for t in range(T):\n",
    "        out[t] = cv2.resize(arr[t], (112,112), interpolation=cv2.INTER_AREA)\n",
    "    out = torch.from_numpy(out).permute(0,3,1,2)  # T,C,112,112\n",
    "    return out\n",
    "\n",
    "def _normalize(frame_tchw: torch.Tensor, mean=(0.45,0.45,0.45), std=(0.225,0.225,0.225)) -> torch.Tensor:\n",
    "    # per-channel normalization\n",
    "    mean = torch.tensor(mean, dtype=frame_tchw.dtype, device=frame_tchw.device)[None,:,None,None]\n",
    "    std  = torch.tensor(std,  dtype=frame_tchw.dtype, device=frame_tchw.device)[None,:,None,None]\n",
    "    return (frame_tchw - mean) / std\n",
    "\n",
    "def uniform_temporal_indices(n_total, clip_len, stride):\n",
    "    # Aim to cover as much as possible; for short videos, loop-pad\n",
    "    if n_total <= 0: return [0]*clip_len\n",
    "    wanted = (clip_len-1)*stride + 1\n",
    "    if n_total >= wanted:\n",
    "        # center-start for consistent coverage\n",
    "        start = (n_total - wanted)//2\n",
    "        return [start + i*stride for i in range(clip_len)]\n",
    "    # not enough frames: repeat last index\n",
    "    idxs = [min(i*stride, n_total-1) for i in range(clip_len)]\n",
    "    return idxs\n",
    "\n",
    "class WLASLDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, clip_len=32, stride=2, train=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.clip_len = clip_len\n",
    "        self.stride = stride\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        row = self.df.iloc[i]\n",
    "        path = row[\"path\"]\n",
    "        label = int(row[\"label\"])\n",
    "        vr = decord.VideoReader(path)\n",
    "        n = len(vr)\n",
    "\n",
    "        idxs = uniform_temporal_indices(n, self.clip_len, self.stride)\n",
    "        batch = vr.get_batch(idxs)  # [T,H,W,C] uint8\n",
    "        # to float [0,1], TCHW\n",
    "        x = batch.float()/255.0\n",
    "        x = x.permute(0,3,1,2)\n",
    "        # spatial resize 112x112\n",
    "        x = _resize_112(x)\n",
    "        # normalize\n",
    "        x = _normalize(x)\n",
    "        return x, label, path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcacc2a-8c41-42c6-b5cd-85b269a21c61",
   "metadata": {},
   "source": [
    "####  Cell 2 — Load manifest & build DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdcdb093-bced-4c3b-98d5-9d2ffc45156a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded manifest: /home/falasoul/notebooks/USD/AAI-590/Capstone/AAI-590-G3-ASL/data/metadata/wlasl100_manifest.csv\n",
      "Total samples: 752\n",
      "Splits: {'train': np.int64(547), 'val': np.int64(124), 'test': np.int64(81)}\n",
      "Classes: 100\n",
      "Train batches: 69 | Val batches: 16 | Test batches: 11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from collections import Counter\n",
    "\n",
    "# === Load dataset manifest (created in 02_preprocess_segments.ipynb) ===\n",
    "MANIFEST = root / \"data\" / \"metadata\" / \"wlasl100_manifest.csv\"\n",
    "m = pd.read_csv(MANIFEST)\n",
    "print(\"Loaded manifest:\", MANIFEST)\n",
    "print(\"Total samples:\", len(m))\n",
    "print(\"Splits:\", dict(m[\"split\"].value_counts()))\n",
    "\n",
    "# === Split subsets ===\n",
    "train_df = m[m[\"split\"] == \"train\"].copy()\n",
    "val_df   = m[m[\"split\"] == \"val\"].copy()\n",
    "test_df  = m[m[\"split\"] == \"test\"].copy()\n",
    "\n",
    "# === Read config values ===\n",
    "clip_len   = CFG[\"model\"][\"clip_len\"]\n",
    "frame_step = CFG[\"model\"][\"frame_stride\"]\n",
    "bs         = CFG[\"train\"][\"batch_size\"]\n",
    "nw         = CFG[\"train\"][\"num_workers\"]\n",
    "\n",
    "# === Import the dataset class (from 03_dataset_preview.ipynb or src/data/wlasl_ds.py) ===\n",
    "# If you have the Dataset defined in the preview notebook, just re-run that cell before this.\n",
    "# Otherwise, place it in `src/data/wlasl_ds.py` and import as shown:\n",
    "# from src.data.wlasl_ds import WLASLDataset\n",
    "\n",
    "# === Create train/val/test datasets ===\n",
    "train_ds = WLASLDataset(train_df, clip_len=clip_len, stride=frame_step, train=True)\n",
    "val_ds   = WLASLDataset(val_df,   clip_len=clip_len, stride=frame_step, train=False)\n",
    "test_ds  = WLASLDataset(test_df,  clip_len=clip_len, stride=frame_step, train=False)\n",
    "\n",
    "# === Handle class imbalance via WeightedRandomSampler ===\n",
    "counts = train_df[\"label\"].value_counts().to_dict()\n",
    "weights = train_df[\"label\"].map(lambda y: 1.0 / max(1, counts[y])).values\n",
    "sampler = WeightedRandomSampler(\n",
    "    torch.tensor(weights, dtype=torch.double),\n",
    "    num_samples=len(train_df),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "# === Build DataLoaders ===\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=bs, sampler=sampler,\n",
    "    num_workers=nw, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=bs, shuffle=False,\n",
    "    num_workers=nw, pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=bs, shuffle=False,\n",
    "    num_workers=nw, pin_memory=True\n",
    ")\n",
    "\n",
    "# === Confirm stats ===\n",
    "num_classes = m[\"label\"].nunique()\n",
    "print(f\"Classes: {num_classes}\")\n",
    "print(f\"Train batches: {len(train_loader)} | Val batches: {len(val_loader)} | Test batches: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071cf9c7-0eb3-4f56-a2fc-be9897883706",
   "metadata": {},
   "source": [
    "### Cell 3 (Notebook) — Small 3D CNN, AMP-ready, compile-ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dbd0ddc-8009-4ab9-adfd-3fe9a7a34757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.compile enabled\n",
      "Params: 2.96M\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# (Optional) Slightly faster matmul on Ada/Lovelace\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "class C3Dlite(nn.Module):\n",
    "    \"\"\"\n",
    "    A compact 3D CNN that trains fast on WLASL100 clips (112x112, T=32).\n",
    "    Input expected as [B, T, C, H, W]; we permute internally to [B, C, T, H, W].\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=100, drop=0.5):\n",
    "        super().__init__()\n",
    "        def block(cin, cout, pool_t=2):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv3d(cin, cout, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm3d(cout),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool3d(kernel_size=(pool_t,2,2), stride=(pool_t,2,2))\n",
    "            )\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv3d(3, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.b1 = block(32,  64, pool_t=2)\n",
    "        self.b2 = block(64, 128, pool_t=2)\n",
    "        self.b3 = block(128, 256, pool_t=2)\n",
    "        self.b4 = block(256, 256, pool_t=2)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool3d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=drop),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):           # x: [B,T,C,H,W]\n",
    "        x = x.permute(0,2,1,3,4)    # -> [B,C,T,H,W]\n",
    "        # ✅ make 5D tensor channels-last for 3D convs (NDHWC)\n",
    "        x = x.contiguous(memory_format=torch.channels_last_3d)\n",
    "        x = self.stem(x)\n",
    "        x = self.b1(x); x = self.b2(x); x = self.b3(x); x = self.b4(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "num_classes = m[\"label\"].nunique()\n",
    "model = C3Dlite(num_classes=num_classes).cuda()\n",
    "\n",
    "# Speed/memory hints\n",
    "#model = model.to(memory_format=torch.channels_last)  # helps on Ada/Lovelace\n",
    "use_compile = True\n",
    "if use_compile:\n",
    "    try:\n",
    "        model = torch.compile(model)  # PyTorch 2.7.1 present in your env\n",
    "        print(\"torch.compile enabled\")\n",
    "    except Exception as e:\n",
    "        print(\"compile skipped:\", e)\n",
    "\n",
    "print(f\"Params: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b53a45d-f2e5-4aee-843c-c2ed7b128eba",
   "metadata": {},
   "source": [
    "#### Cell 4 (Notebook) — Train loop with AMP, checkpoints, resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "283d8af1-044f-42fc-90c3-e5ceaf15402c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs=30 (int)  lr=0.001 (float)  wd=0.0001 (float)  amp_on=True (bool)  grad_acc=1 (int)\n",
      "Epoch 001/30 | train loss 4.8943 top1 0.015 | val loss 4.8427 top1 0.024\n",
      "Epoch 002/30 | train loss 4.7149 top1 0.015 | val loss 4.8105 top1 0.000\n",
      "Epoch 003/30 | train loss 4.6237 top1 0.018 | val loss 4.7979 top1 0.016\n",
      "Epoch 004/30 | train loss 4.5790 top1 0.027 | val loss 4.6666 top1 0.008\n",
      "Epoch 005/30 | train loss 4.5973 top1 0.024 | val loss 4.8655 top1 0.008\n",
      "Epoch 006/30 | train loss 4.6130 top1 0.024 | val loss 4.6790 top1 0.024\n",
      "Epoch 007/30 | train loss 4.5344 top1 0.022 | val loss 4.6636 top1 0.016\n",
      "Epoch 008/30 | train loss 4.4970 top1 0.024 | val loss 4.6514 top1 0.016\n",
      "Epoch 009/30 | train loss 4.5345 top1 0.015 | val loss 4.7258 top1 0.000\n",
      "Epoch 010/30 | train loss 4.5081 top1 0.024 | val loss 4.6124 top1 0.024\n",
      "Epoch 011/30 | train loss 4.4786 top1 0.035 | val loss 4.6409 top1 0.016\n",
      "Epoch 012/30 | train loss 4.4210 top1 0.022 | val loss 4.5000 top1 0.040\n",
      "Epoch 013/30 | train loss 4.4085 top1 0.035 | val loss 4.5546 top1 0.016\n",
      "Epoch 014/30 | train loss 4.4225 top1 0.026 | val loss 4.5328 top1 0.016\n",
      "Epoch 015/30 | train loss 4.3305 top1 0.026 | val loss 4.5529 top1 0.032\n",
      "Epoch 016/30 | train loss 4.4239 top1 0.024 | val loss 4.5441 top1 0.016\n",
      "Epoch 017/30 | train loss 4.3683 top1 0.037 | val loss 4.4876 top1 0.024\n",
      "Epoch 018/30 | train loss 4.3772 top1 0.022 | val loss 4.5001 top1 0.032\n",
      "Epoch 019/30 | train loss 4.2558 top1 0.051 | val loss 4.4690 top1 0.024\n",
      "Epoch 020/30 | train loss 4.2482 top1 0.059 | val loss 4.5066 top1 0.024\n",
      "Epoch 021/30 | train loss 4.2309 top1 0.055 | val loss 4.5045 top1 0.008\n",
      "Epoch 022/30 | train loss 4.2121 top1 0.031 | val loss 4.5260 top1 0.016\n",
      "Epoch 023/30 | train loss 4.2095 top1 0.055 | val loss 4.5125 top1 0.024\n",
      "Epoch 024/30 | train loss 4.2281 top1 0.046 | val loss 4.5844 top1 0.016\n",
      "Epoch 025/30 | train loss 4.1786 top1 0.049 | val loss 4.6434 top1 0.048\n",
      "Epoch 026/30 | train loss 4.2224 top1 0.035 | val loss 4.5280 top1 0.032\n",
      "Epoch 027/30 | train loss 4.1917 top1 0.048 | val loss 4.5569 top1 0.032\n",
      "Epoch 028/30 | train loss 4.0674 top1 0.053 | val loss 4.6381 top1 0.016\n",
      "Epoch 029/30 | train loss 4.1246 top1 0.059 | val loss 4.7566 top1 0.024\n",
      "Epoch 030/30 | train loss 4.1280 top1 0.055 | val loss 4.5576 top1 0.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.amp import autocast, GradScaler       # ✅ new AMP API\n",
    "\n",
    "from src.utils.seed import seed_everything\n",
    "from src.utils.checkpoints import save_checkpoint, load_checkpoint\n",
    "\n",
    "# reproducibility\n",
    "seed_everything(CFG[\"wlasl\"][\"split_seed\"])\n",
    "\n",
    "# --- helpers to safely cast config values ---\n",
    "def as_float(x, default):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def as_int(x, default):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def as_bool(x, default):\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        return x.strip().lower() in {\"1\",\"true\",\"yes\",\"y\",\"on\"}\n",
    "    return bool(x) if x is not None else default\n",
    "\n",
    "# --- parse training parameters from YAML ---\n",
    "epochs   = as_int(CFG[\"train\"].get(\"epochs\", 12), 12)\n",
    "lr       = as_float(CFG[\"train\"].get(\"lr\", 3e-4), 3e-4)\n",
    "wd       = as_float(CFG[\"train\"].get(\"weight_decay\", 0.01), 0.01)\n",
    "amp_on   = as_bool(CFG[\"train\"].get(\"amp\", True), True)\n",
    "grad_acc = as_int(CFG[\"train\"].get(\"grad_accum_steps\", 1), 1)\n",
    "\n",
    "print(f\"epochs={epochs} (int)  lr={lr} (float)  wd={wd} (float)  \"\n",
    "      f\"amp_on={amp_on} (bool)  grad_acc={grad_acc} (int)\")\n",
    "\n",
    "# --- optimizer + scaler ---\n",
    "opt = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "scaler = GradScaler(\"cuda\", enabled=amp_on)     # ✅ new API\n",
    "\n",
    "best_val_top1 = -1.0\n",
    "start_epoch = 0\n",
    "\n",
    "# optional resume checkpoint\n",
    "resume_path = CFG[\"train\"].get(\"resume_checkpoint\", None)\n",
    "if resume_path:\n",
    "    rp = root / resume_path\n",
    "    if rp.exists():\n",
    "        start_epoch, best_val_top1 = load_checkpoint(str(rp), model, opt, scaler)\n",
    "        print(f\"Resumed from {rp} at epoch {start_epoch}, best={best_val_top1:.3f}\")\n",
    "\n",
    "# --- metric helper ---\n",
    "def topk_acc(logits, target, k=1):\n",
    "    with torch.no_grad():\n",
    "        pred = logits.topk(k, dim=1).indices\n",
    "        return (pred.eq(target[:, None]).any(dim=1).float().mean().item())\n",
    "\n",
    "# --- one epoch loop ---\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    total_loss, total_top1, total_n = 0.0, 0.0, 0\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "\n",
    "    for step, (x, y, _) in enumerate(loader):\n",
    "        x = x.cuda(non_blocking=True)\n",
    "        y = y.cuda(non_blocking=True)\n",
    "\n",
    "        with autocast(\"cuda\", enabled=amp_on):   # ✅ updated syntax\n",
    "            logits = model(x)\n",
    "            loss = F.cross_entropy(logits, y) / grad_acc\n",
    "\n",
    "        if train:\n",
    "            scaler.scale(loss).backward()\n",
    "            if (step + 1) % grad_acc == 0:\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            top1 = topk_acc(logits.detach(), y, k=1)\n",
    "            bs = x.size(0)\n",
    "            total_loss += (loss.item() * grad_acc) * bs\n",
    "            total_top1 += top1 * bs\n",
    "            total_n += bs\n",
    "\n",
    "    return total_loss / total_n, total_top1 / total_n\n",
    "\n",
    "# --- training loop ---\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    tr_loss, tr_top1 = run_epoch(train_loader, train=True)\n",
    "    va_loss, va_top1 = run_epoch(val_loader, train=False)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:03d}/{epochs} | \"\n",
    "          f\"train loss {tr_loss:.4f} top1 {tr_top1:.3f} | \"\n",
    "          f\"val loss {va_loss:.4f} top1 {va_top1:.3f}\")\n",
    "\n",
    "    # save checkpoints\n",
    "    state = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optim_state\": opt.state_dict(),\n",
    "        \"scaler_state\": scaler.state_dict(),\n",
    "        \"best_metric\": best_val_top1,\n",
    "    }\n",
    "    save_checkpoint(state, is_best=False, ckpt_dir=str(CKPT_DIR), filename=\"last.pt\")\n",
    "\n",
    "    if va_top1 > best_val_top1:\n",
    "        best_val_top1 = va_top1\n",
    "        save_checkpoint(state, is_best=True, ckpt_dir=str(CKPT_DIR), filename=\"best.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89264e53-a7f4-4e01-a500-0792ea3eea9f",
   "metadata": {},
   "source": [
    "#### Cell 5 (Notebook) — Evaluate best checkpoint on test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f32a87c-79e0-472a-811c-1c35cba0e78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] loss 4.7616 top1 0.025\n"
     ]
    }
   ],
   "source": [
    "# Load best.pt and evaluate on test_loader (AMP-friendly eval)\n",
    "from torch.amp import autocast  # new API\n",
    "\n",
    "best_path = CKPT_DIR / \"best.pt\"\n",
    "if best_path.exists():\n",
    "    _, _ = load_checkpoint(str(best_path), model)  # weights only\n",
    "else:\n",
    "    print(\"best.pt not found, evaluating with current weights.\")\n",
    "\n",
    "model.eval()\n",
    "test_loss, test_top1, n = 0.0, 0.0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y, _ in test_loader:\n",
    "        x = x.cuda(non_blocking=True)\n",
    "        y = y.cuda(non_blocking=True)\n",
    "\n",
    "        # AMP in eval for speed\n",
    "        with autocast(\"cuda\", enabled=True):\n",
    "            logits = model(x)\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        bs = x.size(0)\n",
    "        test_loss += loss.item() * bs\n",
    "        test_top1 += (logits.topk(1, dim=1).indices.squeeze(1) == y).float().sum().item()\n",
    "        n += bs\n",
    "\n",
    "if n > 0:\n",
    "    print(f\"[TEST] loss {test_loss/n:.4f} top1 {test_top1/n:.3f}\")\n",
    "else:\n",
    "    print(\"[TEST] loader is empty; no samples to evaluate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69860812-cfe8-4d5e-bf8b-6e00bbd107fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

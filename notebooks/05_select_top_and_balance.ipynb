{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5aa2fb8",
   "metadata": {},
   "source": [
    "Goals: choose “top-K” most frequent classes for a strong baseline subset; build a balanced manifest; save class weights for training; export buckets for weighted sampler / focal loss / class-balanced loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac3468b",
   "metadata": {},
   "source": [
    "### Cell A — Setup & load final ROI manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84cedef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11980 samples | classes=2000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>path</th>\n",
       "      <th>gloss</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>335</td>\n",
       "      <td>/home/falasoul/notebooks/USD/AAI-590/Capstone/...</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>336</td>\n",
       "      <td>/home/falasoul/notebooks/USD/AAI-590/Capstone/...</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id                                               path    gloss  \\\n",
       "0       335  /home/falasoul/notebooks/USD/AAI-590/Capstone/...  abdomen   \n",
       "1       336  /home/falasoul/notebooks/USD/AAI-590/Capstone/...  abdomen   \n",
       "\n",
       "   label  split  \n",
       "0      2   test  \n",
       "1      2  train  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "root = Path(\"..\").resolve()\n",
    "data_dir = root / \"data\" / \"wlasl_preprocessed\"\n",
    "man_roi = data_dir / \"manifest_nslt2000_roi_final.csv\"   # produced in previous step\n",
    "\n",
    "df = pd.read_csv(man_roi)\n",
    "assert {\"video_id\",\"path\",\"gloss\",\"label\",\"split\"}.issubset(df.columns)\n",
    "print(f\"Loaded {len(df)} samples | classes={df['gloss'].nunique()}\")\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fd676e",
   "metadata": {},
   "source": [
    "### Cell B — Sanity checks (existence, per-split counts, class sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329723b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files: 0\n",
      "Split counts: {'train': 8313, 'val': 2253, 'test': 1414}\n",
      "Classes: 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gloss\n",
       "thin        16\n",
       "cool        16\n",
       "before      16\n",
       "go          15\n",
       "drink       15\n",
       "help        14\n",
       "who         14\n",
       "computer    14\n",
       "cousin      14\n",
       "accident    13\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "# file existence\n",
    "df[\"exists\"] = df[\"path\"].apply(lambda p: os.path.exists(p))\n",
    "missing = df[~df[\"exists\"]]\n",
    "print(f\"Missing files: {len(missing)}\")\n",
    "if len(missing): display(missing.head())\n",
    "\n",
    "# split summary\n",
    "split_counts = df[\"split\"].value_counts().to_dict()\n",
    "print(\"Split counts:\", split_counts)\n",
    "\n",
    "# class sizes overall and per split\n",
    "by_gloss = df.groupby(\"gloss\").size().sort_values(ascending=False)\n",
    "print(\"Classes:\", len(by_gloss))\n",
    "display(by_gloss.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f59bcd0",
   "metadata": {},
   "source": [
    "### Cell C — Choose top-K classes & minimum-per-class requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "022d81c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 104 classes, 1160 samples\n"
     ]
    }
   ],
   "source": [
    "# parameters (tune as needed)\n",
    "TOP_K     = 300          # e.g., 100, 200, 500\n",
    "MIN_PER_C = 10           # only keep classes with >= this many total clips (across all splits)\n",
    "\n",
    "eligible = by_gloss[by_gloss >= MIN_PER_C].index.tolist()\n",
    "topk_gloss = by_gloss.loc[eligible].head(TOP_K).index.tolist()\n",
    "\n",
    "df_top = df[df[\"gloss\"].isin(topk_gloss)].copy()\n",
    "print(f\"Kept {len(topk_gloss)} classes, {len(df_top)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44855578",
   "metadata": {},
   "source": [
    "### New “Cell C+” — Filter out classes without enough clips per split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1691a0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After per-split minima, kept 24 classes and 315 samples\n"
     ]
    }
   ],
   "source": [
    "# Optional sanity filter to drop underrepresented classes before balancing\n",
    "\n",
    "min_per_split = {\"train\": 8, \"val\": 2, \"test\": 1}\n",
    "\n",
    "ok_gloss = []\n",
    "for gloss, gdf in df_top.groupby(\"gloss\"):\n",
    "    ok = True\n",
    "    for split, min_count in min_per_split.items():\n",
    "        if (gdf[\"split\"] == split).sum() < min_count:\n",
    "            ok = False\n",
    "            break\n",
    "    if ok:\n",
    "        ok_gloss.append(gloss)\n",
    "\n",
    "df_top = df_top[df_top[\"gloss\"].isin(ok_gloss)].copy()\n",
    "print(f\"After per-split minima, kept {len(ok_gloss)} classes and {len(df_top)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4602454",
   "metadata": {},
   "source": [
    "You now have:\n",
    "\n",
    "24 sign classes\n",
    "\n",
    "315 total video clips\n",
    "\n",
    "Each class has ≥ 8 train / 2 val / 1 test clips.\n",
    "→ So every class is represented across all splits (which is key for real training and validation).\n",
    "\n",
    "That’s a balanced, compact dataset ideal for:\n",
    "\n",
    "Validating your preprocessing & training loop.\n",
    "\n",
    "Confirming your model learns meaningful patterns (instead of just overfitting to a few examples).\n",
    "\n",
    "Benchmarking FPS, batch sizes, and GPU utilization before scaling up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c4b9e",
   "metadata": {},
   "source": [
    "### Cell D — Balance within each split (cap per-class, drop excess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "638facca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced total: 264 | classes=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1806581/3134896245.py:13: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(n=min(len(g), cap), random_state=42)))\n",
      "/tmp/ipykernel_1806581/3134896245.py:13: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(n=min(len(g), cap), random_state=42)))\n",
      "/tmp/ipykernel_1806581/3134896245.py:13: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(n=min(len(g), cap), random_state=42)))\n"
     ]
    }
   ],
   "source": [
    "# target per-class caps per split (adjust per your dataset)\n",
    "# heuristics: keep natural class proportion across splits but cap extremes\n",
    "per_split_caps = {\n",
    "    \"train\": 8,   # cap max clips/class in train\n",
    "    \"val\":   2,   # cap max in val\n",
    "    \"test\":  1,   # cap max in test\n",
    "}\n",
    "\n",
    "balanced_parts = []\n",
    "for split, cap in per_split_caps.items():\n",
    "    part = df_top[df_top[\"split\"] == split].copy()\n",
    "    part = (part.groupby(\"gloss\", group_keys=False)\n",
    "                 .apply(lambda g: g.sample(n=min(len(g), cap), random_state=42)))\n",
    "    balanced_parts.append(part)\n",
    "\n",
    "df_bal = pd.concat(balanced_parts, ignore_index=True)\n",
    "print(f\"Balanced total: {len(df_bal)} | classes={df_bal['gloss'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373dff26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "990fb841",
   "metadata": {},
   "source": [
    "### Cell E — Verify balance and report class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d329bcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 264\n",
      "By split: {'train': 192, 'val': 48, 'test': 24}\n",
      "\n",
      "Train per-class:\n",
      " count    24.0\n",
      "mean      8.0\n",
      "std       0.0\n",
      "min       8.0\n",
      "25%       8.0\n",
      "50%       8.0\n",
      "75%       8.0\n",
      "max       8.0\n",
      "dtype: float64\n",
      "\n",
      "Val per-class:\n",
      " count    24.0\n",
      "mean      2.0\n",
      "std       0.0\n",
      "min       2.0\n",
      "25%       2.0\n",
      "50%       2.0\n",
      "75%       2.0\n",
      "max       2.0\n",
      "dtype: float64\n",
      "\n",
      "Test per-class:\n",
      " count    24.0\n",
      "mean      1.0\n",
      "std       0.0\n",
      "min       1.0\n",
      "25%       1.0\n",
      "50%       1.0\n",
      "75%       1.0\n",
      "max       1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def report(df_):\n",
    "    print(\"Total:\", len(df_))\n",
    "    print(\"By split:\", df_[\"split\"].value_counts().to_dict())\n",
    "    ctrain = df_[df_[\"split\"]==\"train\"].groupby(\"gloss\").size().describe()\n",
    "    cval   = df_[df_[\"split\"]==\"val\"].groupby(\"gloss\").size().describe()\n",
    "    ctest  = df_[df_[\"split\"]==\"test\"].groupby(\"gloss\").size().describe()\n",
    "    print(\"\\nTrain per-class:\\n\", ctrain)\n",
    "    print(\"\\nVal per-class:\\n\",   cval)\n",
    "    print(\"\\nTest per-class:\\n\",  ctest)\n",
    "\n",
    "report(df_bal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04f55f6",
   "metadata": {},
   "source": [
    "### Cell F — Create class index mapping (label remap) and persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "175382d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved manifest: /home/falasoul/notebooks/USD/AAI-590/Capstone/AAI-590-G3-ASL/data/wlasl_preprocessed/manifest_nslt2000_roi_top24_balanced.csv\n",
      "Saved class map: /home/falasoul/notebooks/USD/AAI-590/Capstone/AAI-590-G3-ASL/data/wlasl_preprocessed/class_index_top24.json\n"
     ]
    }
   ],
   "source": [
    "# Build contiguous class index (0..C-1) in alphabetical order (or by frequency)\n",
    "classes = sorted(df_bal[\"gloss\"].unique())\n",
    "gloss_to_new = {g:i for i,g in enumerate(classes)}\n",
    "df_bal[\"label_new\"] = df_bal[\"gloss\"].map(gloss_to_new)\n",
    "\n",
    "# Save artifacts\n",
    "out_dir = data_dir\n",
    "man_balanced = out_dir / f\"manifest_nslt2000_roi_top{len(classes)}_balanced.csv\"\n",
    "class_map_json = out_dir / f\"class_index_top{len(classes)}.json\"\n",
    "\n",
    "df_bal.to_csv(man_balanced, index=False)\n",
    "print(\"Saved manifest:\", man_balanced)\n",
    "\n",
    "import json\n",
    "with open(class_map_json, \"w\") as f:\n",
    "    json.dump({\"classes\": classes, \"gloss_to_index\": gloss_to_new}, f, indent=2)\n",
    "print(\"Saved class map:\", class_map_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aded11",
   "metadata": {},
   "source": [
    "### Cell G — (Optional) Class weights for imbalanced loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfeab695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved class weights: /home/falasoul/notebooks/USD/AAI-590/Capstone/AAI-590-G3-ASL/data/wlasl_preprocessed/class_weights_top24.json\n"
     ]
    }
   ],
   "source": [
    "# If you want weights for cross-entropy: inverse frequency on train subset\n",
    "train_counts = df_bal[df_bal[\"split\"]==\"train\"][\"gloss\"].value_counts()\n",
    "weights = {gloss_to_new[g]: float(1.0 / c) for g,c in train_counts.items()}\n",
    "import json\n",
    "weights_json = out_dir / f\"class_weights_top{len(classes)}.json\"\n",
    "with open(weights_json, \"w\") as f:\n",
    "    json.dump(weights, f, indent=2)\n",
    "print(\"Saved class weights:\", weights_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f3e92a",
   "metadata": {},
   "source": [
    "### Cell H — (Optional) Spot-check a few files exist and open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e78cefbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spot-check decode OK: 6/6\n"
     ]
    }
   ],
   "source": [
    "import cv2, random\n",
    "\n",
    "sampled = df_bal.sample(min(6, len(df_bal)), random_state=7)\n",
    "ok = 0\n",
    "for p in sampled[\"path\"]:\n",
    "    cap = cv2.VideoCapture(p)\n",
    "    ret, _ = cap.read()\n",
    "    cap.release()\n",
    "    ok += int(ret)\n",
    "print(f\"Spot-check decode OK: {ok}/{len(sampled)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8116abb2",
   "metadata": {},
   "source": [
    "What to do next\n",
    "\n",
    "✅ Proceed to 06_train_baseline.ipynb with this 24-class dataset.\n",
    "\n",
    "Train a small backbone (e.g., R3D-18 or C3D) on these 315 clips.\n",
    "\n",
    "Evaluate convergence and confusion matrix.\n",
    "\n",
    "If training looks stable and accuracy improves over epochs, then you can confidently:\n",
    "\n",
    "Go back to this notebook (05_select_top_and_balance.ipynb)\n",
    "\n",
    "Loosen the filter — e.g.\n",
    "min_per_split = {\"train\": 5, \"val\": 1, \"test\": 1}\n",
    "and maybe TOP_K = 500, MIN_PER_C = 6\n",
    "\n",
    "Regenerate a larger manifest (e.g., 100–300 classes)\n",
    "\n",
    "Re-run training with a deeper backbone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470e2a5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

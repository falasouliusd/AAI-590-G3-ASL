{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb629bf",
   "metadata": {},
   "source": [
    "### Cell A â€” Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1497cf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: /home/falasoul/notebooks/USD/AAI-590/Capstone/AAI-590-G3-ASL/data/wlasl_preprocessed/manifest_nslt2000_roi_top104_balanced_clean.csv\n",
      "Samples: 1159 | classes=104\n",
      "Columns: ['video_id', 'path', 'gloss', 'label', 'split', 'exists', 'label_new']\n",
      "label_new min/max: 0 103\n",
      "label_new nunique: 104\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>path</th>\n",
       "      <th>gloss</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>exists</th>\n",
       "      <th>label_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>639</td>\n",
       "      <td>/home/falasoul/notebooks/USD/AAI-590/Capstone/...</td>\n",
       "      <td>accident</td>\n",
       "      <td>8</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624</td>\n",
       "      <td>/home/falasoul/notebooks/USD/AAI-590/Capstone/...</td>\n",
       "      <td>accident</td>\n",
       "      <td>8</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>632</td>\n",
       "      <td>/home/falasoul/notebooks/USD/AAI-590/Capstone/...</td>\n",
       "      <td>accident</td>\n",
       "      <td>8</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>623</td>\n",
       "      <td>/home/falasoul/notebooks/USD/AAI-590/Capstone/...</td>\n",
       "      <td>accident</td>\n",
       "      <td>8</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65009</td>\n",
       "      <td>/home/falasoul/notebooks/USD/AAI-590/Capstone/...</td>\n",
       "      <td>accident</td>\n",
       "      <td>8</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id                                               path     gloss  \\\n",
       "0       639  /home/falasoul/notebooks/USD/AAI-590/Capstone/...  accident   \n",
       "1       624  /home/falasoul/notebooks/USD/AAI-590/Capstone/...  accident   \n",
       "2       632  /home/falasoul/notebooks/USD/AAI-590/Capstone/...  accident   \n",
       "3       623  /home/falasoul/notebooks/USD/AAI-590/Capstone/...  accident   \n",
       "4     65009  /home/falasoul/notebooks/USD/AAI-590/Capstone/...  accident   \n",
       "\n",
       "   label  split  exists  label_new  \n",
       "0      8  train    True          0  \n",
       "1      8  train    True          0  \n",
       "2      8  train    True          0  \n",
       "3      8  train    True          0  \n",
       "4      8  train    True          0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Cell A â€” Imports, reproducibility, load balanced ROI manifest ===\n",
    "import os, random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Keep CPU threads tame\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "root = Path(\"..\").resolve()\n",
    "data_dir = root / \"data\" / \"wlasl_preprocessed\"\n",
    "\n",
    "# Use the specific balanced ROI manifest you showed\n",
    "man_path = data_dir / \"manifest_nslt2000_roi_top104_balanced_clean.csv\"\n",
    "assert man_path.exists(), f\"Manifest not found: {man_path}\"\n",
    "\n",
    "df = pd.read_csv(man_path)\n",
    "print(\"Loaded:\", man_path)\n",
    "print(f\"Samples: {len(df)} | classes={df['gloss'].nunique()}\")\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "print(\"label_new min/max:\", df[\"label_new\"].min(), df[\"label_new\"].max())\n",
    "print(\"label_new nunique:\", df[\"label_new\"].nunique())\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ea8585",
   "metadata": {},
   "source": [
    "### Cell B â€” WLASLDataset (using ROI + label_new) + WLASLDataset with on-the-fly augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40ea786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell B â€” WLASLDataset (ROI, label_new) with safe loading + on-the-fly augmentation ===\n",
    "import torch, numpy as np, cv2, decord, random\n",
    "from torch.utils.data import Dataset\n",
    "decord.bridge.set_bridge('torch')\n",
    "\n",
    "\n",
    "def _resize_112(frame_tchw: torch.Tensor) -> torch.Tensor:\n",
    "    T, C, H, W = frame_tchw.shape\n",
    "    arr = frame_tchw.permute(0, 2, 3, 1).cpu().numpy()\n",
    "    out = np.empty((T, 112, 112, C), dtype=np.float32)\n",
    "    for t in range(T):\n",
    "        out[t] = cv2.resize(arr[t], (112, 112), interpolation=cv2.INTER_AREA)\n",
    "    return torch.from_numpy(out).permute(0, 3, 1, 2)\n",
    "\n",
    "\n",
    "def _normalize(frame_tchw, mean=(0.45,)*3, std=(0.225,)*3):\n",
    "    mean = torch.tensor(mean, dtype=frame_tchw.dtype, device=frame_tchw.device)[None, :, None, None]\n",
    "    std  = torch.tensor(std,  dtype=frame_tchw.dtype, device=frame_tchw.device)[None, :, None, None]\n",
    "    return (frame_tchw - mean) / std\n",
    "\n",
    "\n",
    "def uniform_temporal_indices(n_total, clip_len, stride):\n",
    "    if n_total <= 0:\n",
    "        return [0] * clip_len\n",
    "    wanted = (clip_len - 1) * stride + 1\n",
    "    if n_total >= wanted:\n",
    "        start = (n_total - wanted) // 2\n",
    "        return [start + i * stride for i in range(clip_len)]\n",
    "    idxs = [min(i * stride, n_total - 1) for i in range(clip_len)]\n",
    "    return idxs\n",
    "\n",
    "\n",
    "class WLASLDataset(Dataset):\n",
    "    def __init__(self, df, clip_len=32, stride=2, train=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.clip_len = clip_len\n",
    "        self.stride = stride\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    # --------- augmentation helpers (on-the-fly, train only) ---------\n",
    "    def _augment(self, frames: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        frames: [T, C, H, W], values in [0,1] (float32).\n",
    "        Only applied when self.train == True.\n",
    "        \"\"\"\n",
    "        if not self.train:\n",
    "            return frames\n",
    "\n",
    "        T, C, H, W = frames.shape\n",
    "\n",
    "        # 1) Random horizontal flip\n",
    "        if random.random() < 0.5:\n",
    "            frames = torch.flip(frames, dims=[3])  # flip width\n",
    "\n",
    "        # 2) Random Gaussian blur\n",
    "        if random.random() < 0.3:\n",
    "            k = random.choice([3, 5])\n",
    "            fr_np = frames.permute(0, 2, 3, 1).cpu().numpy()  # [T,H,W,C]\n",
    "            for t in range(T):\n",
    "                fr_np[t] = cv2.GaussianBlur(fr_np[t], (k, k), 0)\n",
    "            frames = torch.from_numpy(fr_np).permute(0, 3, 1, 2)\n",
    "\n",
    "        # 3) Random brightness / contrast\n",
    "        if random.random() < 0.3:\n",
    "            alpha = 1.0 + 0.4 * (random.random() - 0.5)   # contrast ~ [0.8, 1.2]\n",
    "            beta  = 0.1 * (random.random() - 0.5)         # brightness ~ [-0.05, 0.05]\n",
    "            frames = frames * alpha + beta\n",
    "            frames = frames.clamp(0.0, 1.0)\n",
    "\n",
    "        # 4) Random cutout mask (simulate occlusion)\n",
    "        if random.random() < 0.3:\n",
    "            mask_size = random.randint(16, 40)\n",
    "            y0 = random.randint(0, max(0, H - mask_size))\n",
    "            x0 = random.randint(0, max(0, W - mask_size))\n",
    "            frames[:, :, y0:y0+mask_size, x0:x0+mask_size] = 0.0\n",
    "\n",
    "        return frames\n",
    "\n",
    "    def _safe_load_clip(self, path: str) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Try to read a clip with decord. If anything fails, return a dummy zero clip.\n",
    "        Returned shape: [T, C, H, W], float32 in [0,1].\n",
    "        \"\"\"\n",
    "        try:\n",
    "            vr = decord.VideoReader(path)\n",
    "            n = len(vr)\n",
    "            if n <= 0:\n",
    "                raise RuntimeError(\"no frames\")\n",
    "\n",
    "            idxs = uniform_temporal_indices(n, self.clip_len, self.stride)\n",
    "            batch = vr.get_batch(idxs)        # [T,H,W,C]\n",
    "            x = batch.float() / 255.0         # [0,1]\n",
    "            x = x.permute(0, 3, 1, 2)         # [T,C,H,W]\n",
    "            x = _resize_112(x)                # [T,3,112,112]\n",
    "            x = self._augment(x)              # on-the-fly aug (train only)\n",
    "            x = _normalize(x)                 # final normalization\n",
    "            return x\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to read video {path}: {e} â€” using zero clip.\")\n",
    "            x = torch.zeros(self.clip_len, 3, 112, 112, dtype=torch.float32)\n",
    "            x = _normalize(x)\n",
    "            return x\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        row = self.df.iloc[i]\n",
    "        path = row[\"path\"]\n",
    "        label = int(row[\"label_new\"])   # contiguous 0..C-1\n",
    "\n",
    "        x = self._safe_load_clip(path)\n",
    "        return x, label, path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94cb6cb",
   "metadata": {},
   "source": [
    "#### Cell C â€” Split DataFrames & DataLoaders (single worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8283e08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes: 831 train | 192 val | 136 test\n",
      "Device: cuda\n",
      "Sample batch shape: torch.Size([4, 32, 3, 112, 112]) | labels range: 60 -> 88\n"
     ]
    }
   ],
   "source": [
    "# === Cell C â€” Splits + DataLoaders (no multiprocessing) ===\n",
    "\n",
    "train_df = df[df[\"split\"] == \"train\"].reset_index(drop=True)\n",
    "val_df   = df[df[\"split\"] == \"val\"].reset_index(drop=True)\n",
    "test_df  = df[df[\"split\"] == \"test\"].reset_index(drop=True)\n",
    "\n",
    "print(\"Split sizes:\", len(train_df), \"train |\", len(val_df), \"val |\", len(test_df), \"test\")\n",
    "\n",
    "clip_len = 32\n",
    "stride   = 2\n",
    "batch_size = 4   # small to be safe on GPU\n",
    "\n",
    "train_ds = WLASLDataset(train_df, clip_len=clip_len, stride=stride, train=True)\n",
    "val_ds   = WLASLDataset(val_df,   clip_len=clip_len, stride=stride, train=False)\n",
    "test_ds  = WLASLDataset(test_df,  clip_len=clip_len, stride=stride, train=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,              # ðŸ”’ NO worker processes\n",
    "    pin_memory=(device.type == \"cuda\"),\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=(device.type == \"cuda\"),\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=(device.type == \"cuda\"),\n",
    ")\n",
    "\n",
    "x_dbg, y_dbg, _ = next(iter(train_loader))\n",
    "print(\"Sample batch shape:\", x_dbg.shape, \"| labels range:\", y_dbg.min().item(), \"->\", y_dbg.max().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c013386d",
   "metadata": {},
   "source": [
    "#### Cell D Swap to R(2+1)D-18 (Kinetics-400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e525b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 104\n",
      "Downloading: \"https://download.pytorch.org/models/r2plus1d_18-91a641e6.pth\" to /home/falasoul/.cache/torch/hub/checkpoints/r2plus1d_18-91a641e6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120M/120M [00:01<00:00, 113MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: r2plus1d_18_k400\n"
     ]
    }
   ],
   "source": [
    "# === Cell D â€” R(2+1)D-18 pretrained on Kinetics-400 ===\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models.video import r2plus1d_18, R2Plus1D_18_Weights\n",
    "\n",
    "# Number of classes from manifest\n",
    "num_classes = df[\"label_new\"].nunique()\n",
    "print(\"num_classes:\", num_classes)\n",
    "\n",
    "# Load pretrained weights\n",
    "weights = R2Plus1D_18_Weights.KINETICS400_V1\n",
    "base = r2plus1d_18(weights=weights)\n",
    "\n",
    "# Replace final FC for our 104 glosses\n",
    "in_f = base.fc.in_features\n",
    "base.fc = nn.Linear(in_f, num_classes)\n",
    "\n",
    "# Move to device\n",
    "model = base.to(device)\n",
    "print(\"Model: r2plus1d_18_k400\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0758c3da",
   "metadata": {},
   "source": [
    "#### Cell E â€” Optimizer, Scaler, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c31001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell E â€” Optimizer, scaler, loss (pretrained) ===\n",
    "from torch.amp import GradScaler\n",
    "\n",
    "epochs = 20\n",
    "lr     = 1e-4      # ðŸ”½ slightly lower than 3e-4 used for scratch\n",
    "wd     = 1e-2\n",
    "amp_on = True\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "scaler = GradScaler(enabled=amp_on)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # can keep or remove smoothing\n",
    "best_val_acc = -1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881fd9a6",
   "metadata": {},
   "source": [
    "#### Cell F â€” run_epoch (with correct [B,C,T,H,W] permute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68cf500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell F â€” Metrics + epoch runner (for CNN+BiGRU) ===\n",
    "\n",
    "def top1_acc(logits, y):\n",
    "    return (logits.argmax(1) == y).float().mean().item()\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_acc  = 0.0\n",
    "    total_n    = 0\n",
    "\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "\n",
    "    for x, y, _ in loader:\n",
    "        x = x.to(device, non_blocking=True)  # [B,T,C,H,W]\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        # ðŸ”½ New: permute for 3D CNN\n",
    "        x = x.permute(0, 2, 1, 3, 4).contiguous()  # [B,C,T,H,W]\n",
    "\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=amp_on):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "        if train:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            acc = top1_acc(logits, y)\n",
    "            bs  = x.size(0)\n",
    "            total_loss += loss.item() * bs\n",
    "            total_acc  += acc * bs\n",
    "            total_n    += bs\n",
    "\n",
    "    return total_loss / total_n, total_acc / total_n\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03f005f",
   "metadata": {},
   "source": [
    "#### Cell G â€” Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5efa56b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/20 | train loss 1.3226 acc 0.936 | val loss 3.2730 acc 0.406\n",
      "  âžœ New best val acc=0.406 \n",
      "Epoch 02/20 | train loss 1.1859 acc 0.966 | val loss 3.3076 acc 0.396\n",
      "Epoch 03/20 | train loss 1.1111 acc 0.969 | val loss 3.2866 acc 0.417\n",
      "  âžœ New best val acc=0.417 \n",
      "Epoch 04/20 | train loss 1.0726 acc 0.971 | val loss 3.2002 acc 0.396\n",
      "Epoch 05/20 | train loss 1.0412 acc 0.976 | val loss 3.3046 acc 0.380\n",
      "Epoch 06/20 | train loss 1.0268 acc 0.977 | val loss 3.3609 acc 0.401\n",
      "Epoch 07/20 | train loss 1.0143 acc 0.978 | val loss 3.4485 acc 0.375\n",
      "Epoch 08/20 | train loss 1.0180 acc 0.980 | val loss 3.5573 acc 0.396\n",
      "Epoch 09/20 | train loss 0.9648 acc 0.986 | val loss 3.5597 acc 0.411\n",
      "Epoch 10/20 | train loss 0.9828 acc 0.982 | val loss 3.3082 acc 0.438\n",
      "  âžœ New best val acc=0.438 \n",
      "Epoch 11/20 | train loss 0.9577 acc 0.984 | val loss 3.4350 acc 0.422\n",
      "Epoch 12/20 | train loss 0.9466 acc 0.989 | val loss 3.4187 acc 0.391\n",
      "Epoch 13/20 | train loss 0.9667 acc 0.982 | val loss 3.5652 acc 0.391\n",
      "Epoch 14/20 | train loss 0.9376 acc 0.986 | val loss 3.4205 acc 0.385\n",
      "Epoch 15/20 | train loss 0.9630 acc 0.978 | val loss 3.2487 acc 0.427\n",
      "Epoch 16/20 | train loss 0.9413 acc 0.987 | val loss 3.3495 acc 0.438\n",
      "Epoch 17/20 | train loss 0.9173 acc 0.990 | val loss 3.6324 acc 0.417\n",
      "Epoch 18/20 | train loss 0.8992 acc 0.996 | val loss 3.1877 acc 0.484\n",
      "  âžœ New best val acc=0.484 \n",
      "Epoch 19/20 | train loss 0.9036 acc 0.990 | val loss 3.2591 acc 0.432\n",
      "Epoch 20/20 | train loss 0.9104 acc 0.990 | val loss 3.6644 acc 0.417\n"
     ]
    }
   ],
   "source": [
    "# === Cell G â€” Training Loop ===\n",
    "ckpt_dir = root / \"checkpoints\"\n",
    "ckpt_dir.mkdir(exist_ok=True)\n",
    "\n",
    "best_val_acc = -1.0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, train=True)\n",
    "    va_loss, va_acc = run_epoch(val_loader,   train=False)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d}/{epochs} | \"\n",
    "          f\"train loss {tr_loss:.4f} acc {tr_acc:.3f} | \"\n",
    "          f\"val loss {va_loss:.4f} acc {va_acc:.3f}\")\n",
    "\n",
    "    if va_acc > best_val_acc:\n",
    "        best_val_acc = va_acc\n",
    "        save_path = ckpt_dir / \"best_r2plus1d_k400_top104.pt\"\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"  âžœ New best val acc={best_val_acc:.3f} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6789f1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST â€” loss 3.2564 | acc 0.449\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = root / \"checkpoints\"\n",
    "best_path = ckpt_dir / \"best_r2plus1d_k400_top104.pt\"\n",
    "\n",
    "model.load_state_dict(torch.load(best_path, map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "test_loss, test_acc = run_epoch(test_loader, train=False)\n",
    "print(f\"TEST â€” loss {test_loss:.4f} | acc {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4515dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1a5a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

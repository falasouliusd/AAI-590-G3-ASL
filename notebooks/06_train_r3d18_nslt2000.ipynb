{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "617d04cd",
   "metadata": {},
   "source": [
    "Goal: same staged-unfreeze/AMP/EMA pipeline, now reading ROI manifests, optional topK subset, mixup, focal loss, and weighted sampler. (You already have Cell A/B/C; hereâ€™s what to add/change.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0969f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cell A (Config): set the manifest you want:\n",
    "from pathlib import Path, json\n",
    "root = Path(\"..\").resolve()\n",
    "\n",
    "CONFIG = {\n",
    "  \"manifest\": \"data/wlasl_preprocessed/manifest_nslt2000_roi_top300.csv\",  # or ..._roi.csv for full set\n",
    "  \"clip_len\": 32, \"frame_stride\": 2, \"batch_size\": 16, \"num_workers\": 8,\n",
    "  \"use_weighted_sampler\": True,\n",
    "  \"normalize\": \"kinetics\",\n",
    "  \"epochs\": 50, \"warmup_epochs\": 3,\n",
    "  \"lr_head_stage1\": 1e-3, \"lr_back_stage1\": 0.0,\n",
    "  \"lr_head_stage2\": 1e-4, \"lr_back_stage2\": 3e-5,\n",
    "  \"weight_decay\": 1e-5, \"cosine_eta_min\": 1e-5,\n",
    "  \"amp\": True, \"compile\": True, \"freeze_backbone\": True,\n",
    "  \"unfreeze_at_epoch\": 5, \"unfreeze_scope\": \"layer4\",\n",
    "  \"ema\": True, \"ema_decay\": 0.999,\n",
    "  \"mixup_alpha\": 0.2, \"cutmix_alpha\": 0.0,\n",
    "  \"grad_clip_norm\": 1.0,\n",
    "  \"seed\": 42,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70cacdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell B (Dataset/Loader): same as you used, plus random temporal start offset for training (you already have the patch idea).\n",
    "# losses.py (or inline)\n",
    "import torch, torch.nn as nn\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=1.5, weight=None, reduction=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma; self.weight = weight; self.reduction = reduction\n",
    "        self.ce = nn.CrossEntropyLoss(weight=weight, reduction=\"none\")\n",
    "    def forward(self, logits, target):\n",
    "        ce = self.ce(logits, target)\n",
    "        pt = torch.exp(-ce)\n",
    "        fl = ((1-pt)**self.gamma) * ce\n",
    "        return fl.mean() if self.reduction==\"mean\" else fl.sum()\n",
    "\n",
    "# Load optional weights\n",
    "import json, os\n",
    "weights_path = root/\"runs\"/\"class_weights_top300.json\"\n",
    "if weights_path.exists():\n",
    "    from collections import OrderedDict\n",
    "    w = json.load(open(weights_path))\n",
    "    max_label = max(map(int, w.keys()))\n",
    "    weight_vec = torch.tensor([w.get(str(i), 1.0) for i in range(max_label+1)], dtype=torch.float)\n",
    "else:\n",
    "    weight_vec = None\n",
    "\n",
    "use_focal = True\n",
    "criterion = FocalLoss(gamma=1.5, weight=weight_vec.to(device) if weight_vec is not None else None) \\\n",
    "            if use_focal else nn.CrossEntropyLoss(weight=weight_vec.to(device) if weight_vec is not None else None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
